% vim:ts=1:et:nospell:spelllang=en_gb:ft=tex

 \chapter{Implementation}
  \label{implementation}

  To implement the \emph{ppt2mxp} conversion tool that is the subject of this
  thesis, we chose the Java programming language \citep{gosling-1}, version 8.
  Although the author has significant experience with lots of other, more
  interesting, more compelling, more fun languages, several reasons pushed us
  towards Java, the least of them being its ease of use. Of course, Java
  \emph{is} easy to use --- it would not have become as popular as it is
  nowadays if it wasn't. It has a fairly clear and logical syntax, a consistent
  structure, and an extensive standard library. At conception in 1995, its
  performance was abysmal, but throughout the years it has steadily improved
  and somewhere between Java 5 (then still called 1.5) and 6 (when they dropped
  the `1.' prefix) it became an industry standard.

  Quite a number of IDEs have been created to further improve developers'
  experience working with Java. Netbeans, Eclipse and IntelliJ come to mine,
  although there are many others, and of course you can still write Java using
  a standard (or advanced) text editor such as Notepad or VIM. While the author
  usually prefers the latter for any kind of text editing --- this very
  document was written entirely using VIM --- the weapon of choice when it
  comes to Java is currently IntelliJ. The way IntelliJ practically writes more
  than half of the code automatically for you is something no other IDE has
  been able to match. Naturally, this is the author's personal opinion and
  should not be seen as fact, but if you're looking for a new Java IDE, it's
  definitely worth checking out. The prospect of using IntelliJ for this thesis
  has definitely contributed to the decision of using Java. It should be noted
  that, had another Java IDE been required, this thesis might never have seen
  the light of day.

  The vast and extensive amount of libraries available for Java was obviously
  one of the more important reasons to make this choice. The existence of the
  Apache POI library (see section \ref{poi}) was a huge help in reaching our
  goal; without it, we would have had to figure out the very obfuscated .ppt
  file format structure, which undoubtedly would have taken up more time than
  was available to us. Other libraries like Spring, which allows the programmer
  to use and reuse components without writing complex systems to instantiate
  them, further increased our resolve to make Java our primary technology
  choice.

  However, Java is not the only technology used here. \mxp is written entirely
  in HTML5, so any tool that somehow relates to \mxp sooner or later needs to
  use HTML5 as well. The widely accepted HTML5 standard makes \mxp
  presentations highly portable and runnable on any device with a recent web
  browser, including smartphones and tablets \citep{roels-1}.

  In the following sections we discuss how the various technologies were used
  to create the \emph{ppt2mxp} tool.

  \section{Taking \ppt apart}
   \label{poi}

   When converting one file format into another, the first part of the process
   involves getting the data you need out of the original file. This can be
   very complicated, as some --- usually proprietary --- file formats are
   deliberately designed to discourage this. They obfuscate data, encrypt it,
   and structure it in illogical and unexpected ways, amongst other techniques.
   The \ppt file format unfortunately is such a format, as Microsoft wouldn't
   want to risk other companies making software that would work with \ppt
   files. Of course, over the years people have managed to crack the format,
   enabling the conversion of \ppt presentations into other formats, although
   the conversion does not usually guarantee to yield results that mimic the
   original version perfectly. Luckily, we don't want a perfect conversion, we
   want a better one.

   We found Apache POI library very helpful in this part of the implementation.
   The POI\footnote{Originally ``Poor Obfuscation Implementation''
   \citep{sundaram-1}} Library is a Java library that provides an API to access
   Microsoft document formats. The most mature (and most popular) part of it is
   HSSF\footnote{Horrible SpreadSheet Format}, which is used by Java developers
   worldwide to access Microsoft Excel spreadsheet data, as well as export data
   into Excel spreadsheets.

   For our purposes, we relied on HSLF\footnote{``Horrible SLideshow Format''},
   which provided us with a full API to access the contents of a \ppt
   presentation's contents in a myriad of ways. We could access all images at
   once, or every bit of text from the whole presentation, but the most
   interesting to us was the ability to access contents on a per-slide basis.
   Getting a list of the slides in a presentation first allowed us to group
   contents within their immediate context, under a node per slide in our
   component tree. As such, we could loop over the presentation's slides,
   converting them one by one, by placing the contents of each slide in a \mxp
   slide equivalent.

   \subsection{Bullets}

    That was unfortunately not the end of it. While HSLF does give us access to
    all the text in a presentation, or per slide, it was not immediately clear
    to us how it distinguished between `normal' text and bullet lists. This
    meant for a long time our conversion process was incomplete, as all bullets
    from the original \ppt presentation appeared as incoherent text runs in our
    converted result. We found out about the \code{RichTextRun} class, which
    had all the tools and properties to detect bullets and their indentation
    level, but we only discovered very recently that we could extract
    \code{RichTextRun}s from the \code{TextShape}s we were getting out of the
    slides.

    % TODO more whining about bullets, show some code of that awesome stack we use to create nested bullet lists

   \subsection{Animations}

    Another challenge was dealing with animations and other ways people managed
    to put way more content on one slide than would be advisable. The
    animations could not be transferred to \mxp since \mxp has its own way of
    transitioning from each component to the next in the form of a
    ZUI\footnote{Zoomable User Interface}. It would technically be possible to
    implement additional animations as a separate plug-in for \mxp to provide
    the equivalents of the animations in \ppt*, but that is beyond the scope of
    this thesis. So we could not provide the same animations, but some people
    use those animations not just to show off but to actually show multiple
    pictures and blocks of text, one after the other, on the same slide.
    Without animations, this content would either not be visible or it would
    become a serious layout issue in \mxp.
   
    Our first solution tried to limit the amount of objects one slide can
    contain, and any additional content should be put on extra slides
    automatically. A downside of this is that we had no way of guessing the
    correct order in which the content should appear, so what may have been an
    intrinsic choreography of pictures in \ppt might become an incoherent
    jumble of images in \mxp. Another solution would be to scale all content
    until it all fits next to each other on one slide, and then rely on the ZUI
    to show the pictures one by one, but in this case the same problem with
    order of appearance manifests itself. In the end, we decided it would be
    best to accept that no conversion algorithm is going to be perfect, and the
    author can always manually change the order around after the conversion is
    done.

    With this in mind, we now render the components in the order we get them
    from HSLF, hoping that this resembles the original order closely. The
    automated layout takes care of any overlapping that might have occurred
    originally, so we don't have to worry about that.

  \section{Generating \mxp}

   Generating \mxp presentations was the final goal of the first phase of this
   thesis. This seemed a fairly easy task at first, until we learned that the
   \mxp compiler would not be available to us for most of the year. This meant
   we would either not be able to view-test our generated presentations, or we
   would have to convert them to browser-ready HTML5 ourselves. We chose the
   latter option, as not being able to see our results would not be very
   helpful in implementing and tweaking our conversion tool. As a result, this
   task became much more complicated, as we had to emulate the compiler's work
   ourselves. Luckily we already decided we would be working with a Java object
   representation of the original presentation as an intermediary form, a
   so-called component tree, which meant we could easily change the output of
   our conversion tool without affecting the rest of the conversion process,
   and on a per-component basis.

%   TODO generating

   \subsection{Playing \mxp compiler}

    Since the \mxp compiler was not functional during most of this thesis'
    implementation, we decided to generate an HTML5 file much like the \mxp
    compiler would, including the \mxp JavaScript library and plug-ins. This
    required us to first learn how \mxp works on the inside, which proved to be
    a steep learning curve but gave us more insight into the software than we
    would've gotten if we only had to generate \mxp XML and leave the rest to
    the compiler.

    \subsubsection{Improving the ZUI}
   
     As an exercise, we changed the way the ZUI works. Originally, \mxp used
     the CSS3 \code{transform: scale()} property to enlarge or reduce the whole
     view, giving the impression of zooming in or out. This is an obvious
     approach, simple in its execution and quite foolproof. However, the
     downside is that you can't zoom in very much, because currently browsers
     do not leverage the advantage of vector graphics and fonts even if you do
     use them, and obviously raster-based content doesn't scale much anyway.
     Instead, browsers render the content at its initial scale, and then treat
     the result as one big image when scaled or otherwise transformed
     afterwards. This means you get extremely pixelated content when zooming in
     too much.

     Through some refactoring, we were able to change this to use the
     \code{transform: translateZ()} property instead, along with the
     \code{transform: perspective()}\footnote{Not to be confused with the
     \code{perspective: \[number\]} property, which yields different results}
     and the \code{transform-style: preserve-3d} properties. This means we're
     now effectively rendering the presentation in 3D, and moving our viewpoint
     around in the 3D space to center each slide or component in turn.

     We believe this opens the door for even more visually impressive
     presentations, where content can be placed on different points along the
     Z-axis. This allows for example to place multiple slides behind one
     another, making for impressive zoom transitions between slides. The
     downside of this is that the overview may not always show all content, as
     some content can overlap, but we trust the author uses this feature wisely
     when manually adjusting the position of their slides. It may for example
     be useful to group slides together in this way, when there is too much
     content to show on one slide but creating a second, separate slide may
     break the flow of the presentation. In any case, our automated layout
     plugin won't currently generate slides positioned this way.

    \subsubsection{Plain HTML5}

     % TODO write about how we wrote HTML5 like neanderthals

   \subsection{\mxp XML}

%    TODO XML

  \section{Creating layouts}

%   TODO layout

   \subsection{Using constraints}

%    TODO constraints

   \subsection{Other ways}

%    TODO other ways

%   15:50 <omega> zeg, ik zit nu al een hele tijd thesis te schrijven en de laatste paar dagen vooral te zeveren over layout, maar intussen doe ik nog ni echt iets van layout, met t gedacht van ik schrijf daar binnenkort ne mindxpres plug-in voor en klaar
%   15:51 <omega> maar wordt layout momenteel eig ni mostly door de compiler gedaan?
%   15:52 <omega> ben zo eens naar de presentation.js libs en code gaan kijken, en ik zie ni direct een manier om ne plug-in layout te laten doen, aangezien plug-ins mostly component-specifiek zijn en ni alle componenten kunnen aansturen
%   15:53 <omega> dus klopt het dat ik ofwel de compiler moet aanpassen, ofwel presentation.js hacken om dat soort plug-ins toe te laten?
%   15:53 <omega> of laat het dat soort plug-ins al toe maar zijn er gewoon nog geen?
%   16:30 <omega> de 'structured' plug-in doet wel layout van slides, maar binnen die slides zie ik niet meteen een systeem dat layout regelt, met templates of otherwise, het pakt gewoon de coordinaten en afmetingen die de compiler bepaald heeft
%   16:31 <omega> al zou die slide plug-in wel *kunnen* prutsen met die layout... dus mss moet ik gwn de slide plug-in uitbreiden/hacken/vervangen
%   13:22 <reinout> ik zou een container plug-in maken
%   13:22 <reinout> gelijk de slide
%   13:22 <reinout> maar dan onzichtbaar
%   13:23 <reinout> want containers kan je nesten
%   13:23 <reinout> dus een slide kan bv uw layout container bevatten, die dan de children een layout geeft
%   13:23 <reinout> maar op die manier is uw layout ding bruikbaar buiten slides
%   13:24 <reinout> (alternatief was uw layout stuff in de slide plug-in steken)
%   13:31 <omega> oeh, cool idee indeed, beter dan de slide plug-in abusen
